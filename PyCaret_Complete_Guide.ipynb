{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Complete Guide to PyCaret and Streamlit for Machine Learning\n",
    "\n",
    "**Author:** Victor Bolade - Data Science Lead Instructor\n",
    "\n",
    "**Date:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "1. What is PyCaret and why it's powerful\n",
    "2. What is Streamlit and how to deploy ML models\n",
    "3. Complete ML workflow with PyCaret\n",
    "4. Multiple approaches (flexible vs rigid)\n",
    "5. Handling imbalanced datasets\n",
    "6. Production-ready code examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1Ô∏è‚É£ What is PyCaret?\n",
    "\n",
    "## üìñ Definition\n",
    "\n",
    "**PyCaret** is an open-source, **low-code** machine learning library in Python that automates machine learning workflows.\n",
    "\n",
    "## üöÄ Why Use PyCaret?\n",
    "\n",
    "### Traditional ML Workflow (Without PyCaret)\n",
    "```python\n",
    "# You have to write 100+ lines of code\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Handle categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "predictions = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n",
    "```\n",
    "\n",
    "### Same Workflow with PyCaret (Just 5 Lines!)\n",
    "```python\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Setup (handles everything: encoding, scaling, splitting)\n",
    "clf = setup(data=data, target='target', session_id=42)\n",
    "\n",
    "# Train and compare ALL models automatically\n",
    "best_model = compare_models()\n",
    "\n",
    "# Done! ‚úÖ\n",
    "```\n",
    "\n",
    "## üéØ Key Features of PyCaret\n",
    "\n",
    "1. **Automated Data Preprocessing** - Handles missing values, encoding, scaling\n",
    "2. **Model Comparison** - Tests 15+ algorithms in one line\n",
    "3. **Hyperparameter Tuning** - Automatic optimization\n",
    "4. **Model Deployment** - Easy integration with Streamlit, Flask, FastAPI\n",
    "5. **Imbalance Handling** - Built-in SMOTE and other techniques\n",
    "6. **Cross-Validation** - Automatic k-fold CV\n",
    "\n",
    "## üì¶ What Can You Build with PyCaret?\n",
    "\n",
    "- **Classification** - Customer churn, fraud detection, disease diagnosis\n",
    "- **Regression** - House price prediction, sales forecasting\n",
    "- **Clustering** - Customer segmentation\n",
    "- **Anomaly Detection** - Fraud detection, network intrusion\n",
    "- **Time Series** - Stock price prediction, demand forecasting\n",
    "- **NLP** - Sentiment analysis, text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ What is Streamlit?\n",
    "\n",
    "## üìñ Definition\n",
    "\n",
    "**Streamlit** is an open-source Python framework that lets you **create interactive web applications** for machine learning and data science projects **without any frontend knowledge** (no HTML, CSS, or JavaScript needed!).\n",
    "\n",
    "## üöÄ Why Use Streamlit?\n",
    "\n",
    "### Traditional Web App (Flask/Django)\n",
    "```python\n",
    "# Flask - You need to write HTML, CSS, JavaScript\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')  # Need to create HTML file\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Complex form handling\n",
    "    data = request.form.to_dict()\n",
    "    # More code...\n",
    "```\n",
    "\n",
    "### Same App with Streamlit (Pure Python!)\n",
    "```python\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"My ML App\")\n",
    "age = st.number_input(\"Enter age\")\n",
    "if st.button(\"Predict\"):\n",
    "    prediction = model.predict([[age]])\n",
    "    st.write(f\"Result: {prediction}\")\n",
    "```\n",
    "\n",
    "## üéØ Key Features of Streamlit\n",
    "\n",
    "1. **Pure Python** - No HTML/CSS/JavaScript needed\n",
    "2. **Interactive Widgets** - Sliders, buttons, file uploaders, text inputs\n",
    "3. **Data Visualization** - Charts, plots, maps\n",
    "4. **Fast Deployment** - Deploy to Streamlit Cloud for free\n",
    "5. **Real-time Updates** - Changes reflect immediately\n",
    "6. **Session State** - Maintain user data across interactions\n",
    "\n",
    "## üåü Perfect Combination: PyCaret + Streamlit\n",
    "\n",
    "**PyCaret** - Build and train your ML model\n",
    "\n",
    "**Streamlit** - Deploy your model as a web app\n",
    "\n",
    "**Result** - Production-ready ML application in minutes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ Installation\n",
    "\n",
    "## Step 1: Create Conda Environment (Recommended)\n",
    "\n",
    "```bash\n",
    "# Create environment\n",
    "conda create -n pycaret_env python=3.10 -y\n",
    "\n",
    "# Activate environment\n",
    "conda activate pycaret_env\n",
    "\n",
    "# Navigate to safe directory\n",
    "cd %USERPROFILE%  # Windows\n",
    "cd ~  # Mac/Linux\n",
    "```\n",
    "\n",
    "## Step 2: Fix SSL Issues (For Nigerian Networks)\n",
    "\n",
    "```bash\n",
    "conda config --set ssl_verify false\n",
    "pip install --upgrade pip setuptools wheel\n",
    "pip config set global.timeout 100\n",
    "```\n",
    "\n",
    "## Step 3: Install PyCaret and Streamlit\n",
    "\n",
    "```bash\n",
    "# Install PyCaret\n",
    "pip install pycaret\n",
    "\n",
    "# If it fails, use:\n",
    "pip install pycaret --no-cache-dir\n",
    "\n",
    "# Install Streamlit\n",
    "pip install streamlit\n",
    "```\n",
    "\n",
    "## Step 4: Verify Installation\n",
    "\n",
    "```python\n",
    "# Test PyCaret\n",
    "from pycaret.classification import *\n",
    "print(\"‚úÖ PyCaret installed successfully!\")\n",
    "\n",
    "# Test Streamlit\n",
    "import streamlit as st\n",
    "print(\"‚úÖ Streamlit installed successfully!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import *\n",
    "\n",
    "# Verify imports\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ Understanding PyCaret Algorithms\n",
    "\n",
    "## üìä Classification Algorithms Available in PyCaret\n",
    "\n",
    "When you run `compare_models()`, PyCaret automatically tests these algorithms:\n",
    "\n",
    "| **Algorithm ID** | **Full Name** | **Best For** |\n",
    "|------------------|---------------|---------------|\n",
    "| `lr` | Logistic Regression | Simple, interpretable models |\n",
    "| `knn` | K-Nearest Neighbors | Pattern recognition |\n",
    "| `nb` | Naive Bayes | Text classification, spam detection |\n",
    "| `dt` | Decision Tree | Interpretable, handles non-linear data |\n",
    "| `svm` | Support Vector Machine | High-dimensional data |\n",
    "| `rbfsvm` | SVM with RBF Kernel | Non-linear classification |\n",
    "| `gpc` | Gaussian Process | Small datasets, uncertainty estimates |\n",
    "| `mlp` | Multi-Layer Perceptron | Neural networks |\n",
    "| `ridge` | Ridge Classifier | Regularized linear models |\n",
    "| `rf` | Random Forest | Most versatile, handles everything |\n",
    "| `qda` | Quadratic Discriminant | Non-linear decision boundaries |\n",
    "| `ada` | AdaBoost | Boosting weak learners |\n",
    "| `gbc` | Gradient Boosting | High accuracy, slower training |\n",
    "| `lda` | Linear Discriminant | Dimensionality reduction + classification |\n",
    "| `et` | Extra Trees | Like Random Forest but faster |\n",
    "| `xgboost` | XGBoost | Industry standard, Kaggle winner |\n",
    "| `lightgbm` | LightGBM | Fast gradient boosting |\n",
    "| `catboost` | CatBoost | Handles categorical data well |\n",
    "\n",
    "## üéØ How to Know Which Algorithm Was Selected?\n",
    "\n",
    "```python\n",
    "# After running compare_models()\n",
    "best_model = compare_models()\n",
    "\n",
    "# Print the algorithm name\n",
    "print(f\"Best Algorithm: {type(best_model).__name__}\")\n",
    "print(f\"Full Details: {best_model}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5Ô∏è‚É£ Complete ML Workflow with PyCaret\n",
    "\n",
    "## üóÇÔ∏è Dataset: Customer Churn Prediction\n",
    "\n",
    "We'll use a **Telco Customer Churn** dataset to predict which customers will leave (churn).\n",
    "\n",
    "**Business Problem:** A telecommunications company wants to identify customers who are likely to cancel their subscription.\n",
    "\n",
    "**Target Variable:** `Churn` (Yes/No)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 1: Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data (you can replace this with your own CSV)\n",
    "# For demonstration, let's create a sample dataset\n",
    "\n",
    "# In real scenario, you would load like this:\n",
    "# data = pd.read_csv(\"customer_churn.csv\")\n",
    "\n",
    "# Sample data creation for demo\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'customerID': [f'CUST{i:04d}' for i in range(1, 1001)],\n",
    "    'gender': np.random.choice(['Male', 'Female'], 1000),\n",
    "    'SeniorCitizen': np.random.choice([0, 1], 1000),\n",
    "    'Partner': np.random.choice(['Yes', 'No'], 1000),\n",
    "    'Dependents': np.random.choice(['Yes', 'No'], 1000),\n",
    "    'tenure': np.random.randint(1, 72, 1000),\n",
    "    'PhoneService': np.random.choice(['Yes', 'No'], 1000),\n",
    "    'MultipleLines': np.random.choice(['Yes', 'No', 'No phone service'], 1000),\n",
    "    'InternetService': np.random.choice(['DSL', 'Fiber optic', 'No'], 1000),\n",
    "    'OnlineSecurity': np.random.choice(['Yes', 'No', 'No internet service'], 1000),\n",
    "    'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], 1000),\n",
    "    'PaperlessBilling': np.random.choice(['Yes', 'No'], 1000),\n",
    "    'PaymentMethod': np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], 1000),\n",
    "    'MonthlyCharges': np.random.uniform(20, 120, 1000),\n",
    "    'TotalCharges': np.random.uniform(100, 8000, 1000),\n",
    "    'Churn': np.random.choice(['Yes', 'No'], 1000, p=[0.27, 0.73])  # 27% churn rate (realistic)\n",
    "})\n",
    "\n",
    "# Display first few rows\n",
    "print(\"üìä Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Display dataset info\n",
    "print(\"\\nüìà Dataset Information:\")\n",
    "print(data.info())\n",
    "\n",
    "# Display target distribution\n",
    "print(\"\\nüéØ Target Variable Distribution:\")\n",
    "print(data['Churn'].value_counts())\n",
    "print(\"\\nChurn Rate:\")\n",
    "print(data['Churn'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Step 2: Data Cleaning (MUST DO BEFORE PYCARET!)\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT:** Always clean your data BEFORE using PyCaret.\n",
    "\n",
    "Common cleaning steps:\n",
    "1. Remove unnecessary columns (like IDs)\n",
    "2. Handle missing values\n",
    "3. Fix data types\n",
    "4. Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DATA CLEANING =====\n",
    "\n",
    "print(\"üßπ Starting Data Cleaning...\\n\")\n",
    "\n",
    "# 1. Remove unnecessary columns\n",
    "print(\"1Ô∏è‚É£ Removing customerID column (not predictive)\")\n",
    "data_clean = data.drop(columns=['customerID'])\n",
    "\n",
    "# 2. Check for missing values\n",
    "print(\"\\n2Ô∏è‚É£ Checking for missing values:\")\n",
    "print(data_clean.isnull().sum())\n",
    "\n",
    "# 3. Fix TotalCharges column (common issue in telecom datasets)\n",
    "print(\"\\n3Ô∏è‚É£ Converting TotalCharges to numeric (if it's not already)\")\n",
    "data_clean['TotalCharges'] = pd.to_numeric(data_clean['TotalCharges'], errors='coerce')\n",
    "\n",
    "# 4. Check for missing values again\n",
    "missing_after = data_clean.isnull().sum()\n",
    "if missing_after.sum() > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Found {missing_after.sum()} missing values:\")\n",
    "    print(missing_after[missing_after > 0])\n",
    "    print(\"\\nPyCaret will handle these automatically during setup() ‚úÖ\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No missing values found!\")\n",
    "\n",
    "# 5. Check for duplicates\n",
    "duplicates = data_clean.duplicated().sum()\n",
    "print(f\"\\n4Ô∏è‚É£ Checking for duplicates: {duplicates} found\")\n",
    "if duplicates > 0:\n",
    "    data_clean = data_clean.drop_duplicates()\n",
    "    print(\"‚úÖ Duplicates removed\")\n",
    "\n",
    "# 6. Verify data types\n",
    "print(\"\\n5Ô∏è‚É£ Data Types:\")\n",
    "print(data_clean.dtypes)\n",
    "\n",
    "print(\"\\n‚úÖ Data cleaning complete!\")\n",
    "print(f\"Final dataset shape: {data_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6Ô∏è‚É£ PyCaret Model Training - TWO APPROACHES\n",
    "\n",
    "## üîÄ Approach 1: Using `compare_models()` (Automated)\n",
    "\n",
    "**When to use:**\n",
    "- You don't know which algorithm works best\n",
    "- You want to try multiple models quickly\n",
    "- You want PyCaret to recommend the best algorithm\n",
    "\n",
    "**Pros:**\n",
    "- Saves time\n",
    "- Tests 15+ algorithms automatically\n",
    "- Finds the best model based on your metric\n",
    "\n",
    "**Cons:**\n",
    "- Takes longer to run\n",
    "- Less control over which model is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup PyCaret Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== APPROACH 1: USING COMPARE_MODELS =====\n",
    "\n",
    "print(\"üöÄ Setting up PyCaret environment...\\n\")\n",
    "\n",
    "# Setup PyCaret\n",
    "clf1 = setup(\n",
    "    data=data_clean,\n",
    "    target='Churn',\n",
    "    session_id=42,  # For reproducibility\n",
    "    \n",
    "    # ===== DATA PREPROCESSING =====\n",
    "    normalize=True,  # Scale numeric features (StandardScaler)\n",
    "    transformation=False,  # Don't apply power transformations\n",
    "    \n",
    "    # ===== CATEGORICAL ENCODING =====\n",
    "    categorical_features=['gender', 'Partner', 'Dependents', 'PhoneService', \n",
    "                         'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
    "                         'Contract', 'PaperlessBilling', 'PaymentMethod'],\n",
    "    \n",
    "    # ===== NUMERIC FEATURES =====\n",
    "    numeric_features=['tenure', 'MonthlyCharges', 'TotalCharges'],\n",
    "    \n",
    "    # ===== IMBALANCE HANDLING =====\n",
    "    # OPTION 1: Handle imbalance (use if target is imbalanced)\n",
    "    fix_imbalance=True,  # Uses SMOTE automatically\n",
    "    \n",
    "    # OPTION 2: Don't handle imbalance (use if target is balanced)\n",
    "    # fix_imbalance=False,\n",
    "    \n",
    "    # ===== OUTLIER REMOVAL =====\n",
    "    remove_outliers=False,  # Set to True if you want to remove outliers\n",
    "    \n",
    "    # ===== MULTICOLLINEARITY =====\n",
    "    remove_multicollinearity=True,  # Remove highly correlated features\n",
    "    multicollinearity_threshold=0.9,\n",
    "    \n",
    "    # ===== UNKNOWN CATEGORIES =====\n",
    "    handle_unknown_categorical=True,  # Important for deployment!\n",
    "    \n",
    "    # ===== SILENT MODE =====\n",
    "    silent=True,  # Don't show setup summary (set to False to see details)\n",
    "    \n",
    "    # ===== VERBOSITY =====\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ PyCaret setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all available models\n",
    "print(\"\\nüîç Comparing all classification algorithms...\\n\")\n",
    "\n",
    "best_model_1 = compare_models(\n",
    "    sort='Accuracy',  # Can also use 'AUC', 'F1', 'Recall', 'Precision'\n",
    "    n_select=1,  # Return top 1 model (can select top 3 with n_select=3)\n",
    "    fold=5,  # 5-fold cross-validation (default is 10)\n",
    "    # exclude=['knn', 'nb'],  # Optional: exclude specific models\n",
    "    turbo=True  # Faster comparison (uses fewer iterations)\n",
    ")\n",
    "\n",
    "# Display which algorithm was selected\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"üèÜ BEST ALGORITHM SELECTED: {type(best_model_1).__name__}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nFull Model Details:\\n{best_model_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the Best Model (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== OPTIONAL: HYPERPARAMETER TUNING =====\n",
    "\n",
    "print(\"\\nüéØ Tuning hyperparameters...\\n\")\n",
    "\n",
    "tuned_model_1 = tune_model(\n",
    "    best_model_1,\n",
    "    optimize='Accuracy',  # Metric to optimize\n",
    "    n_iter=10,  # Number of iterations (higher = better but slower)\n",
    "    fold=5  # Cross-validation folds\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize model (train on full dataset)\n",
    "print(\"\\nüì¶ Finalizing model...\")\n",
    "\n",
    "# Choose whether to use tuned or untuned model\n",
    "# OPTION 1: Use tuned model\n",
    "final_model_1 = finalize_model(tuned_model_1)\n",
    "\n",
    "# OPTION 2: Use untuned model (skip tuning step)\n",
    "# final_model_1 = finalize_model(best_model_1)\n",
    "\n",
    "print(\"‚úÖ Model finalized!\\n\")\n",
    "\n",
    "# Save the model\n",
    "print(\"üíæ Saving model...\")\n",
    "save_model(final_model_1, 'churn_model_compare')\n",
    "print(\"‚úÖ Model saved as 'churn_model_compare.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Approach 2: Using Specific Model (Manual)\n",
    "\n",
    "**When to use:**\n",
    "- You already know which algorithm to use\n",
    "- You want faster training\n",
    "- Your boss/client requested a specific algorithm\n",
    "- You want more control\n",
    "\n",
    "**Pros:**\n",
    "- Faster (trains only one model)\n",
    "- Full control over algorithm choice\n",
    "- Better for production when you know what works\n",
    "\n",
    "**Cons:**\n",
    "- You might miss a better algorithm\n",
    "- Requires domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== APPROACH 2: USING SPECIFIC MODEL =====\n",
    "\n",
    "print(\"\\nüéØ Training specific model (Random Forest)...\\n\")\n",
    "\n",
    "# Setup PyCaret again (required if you want to train a new model)\n",
    "clf2 = setup(\n",
    "    data=data_clean,\n",
    "    target='Churn',\n",
    "    session_id=42,\n",
    "    normalize=True,\n",
    "    fix_imbalance=True,\n",
    "    silent=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Create specific model\n",
    "# Options: 'lr', 'knn', 'nb', 'dt', 'rf', 'xgboost', 'lightgbm', 'catboost', etc.\n",
    "\n",
    "# Example 1: Random Forest\n",
    "rf_model = create_model('rf', fold=5)\n",
    "\n",
    "# Example 2: XGBoost (uncomment to use)\n",
    "# xgb_model = create_model('xgboost', fold=5)\n",
    "\n",
    "# Example 3: Logistic Regression (uncomment to use)\n",
    "# lr_model = create_model('lr', fold=5)\n",
    "\n",
    "print(f\"\\n‚úÖ Model created: {type(rf_model).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Tune the model\n",
    "print(\"\\nüéØ Tuning Random Forest...\\n\")\n",
    "\n",
    "tuned_rf = tune_model(\n",
    "    rf_model,\n",
    "    optimize='AUC',  # Changed to AUC for imbalanced datasets\n",
    "    n_iter=10\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tuning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize and save\n",
    "print(\"\\nüì¶ Finalizing Random Forest model...\")\n",
    "\n",
    "# OPTION 1: Use tuned model\n",
    "final_rf = finalize_model(tuned_rf)\n",
    "\n",
    "# OPTION 2: Use untuned model (uncomment to skip tuning)\n",
    "# final_rf = finalize_model(rf_model)\n",
    "\n",
    "print(\"‚úÖ Model finalized!\\n\")\n",
    "\n",
    "# Save the model\n",
    "print(\"üíæ Saving model...\")\n",
    "save_model(final_rf, 'churn_model_rf_specific')\n",
    "print(\"‚úÖ Model saved as 'churn_model_rf_specific.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7Ô∏è‚É£ Model Evaluation and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "print(\"üìä Evaluating model performance...\\n\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_model(final_rf, plot='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plot_model(final_rf, plot='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "plot_model(final_rf, plot='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "predictions = predict_model(final_rf)\n",
    "print(\"\\nüîÆ Sample Predictions:\")\n",
    "print(predictions[['Churn', 'prediction_label', 'prediction_score']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8Ô∏è‚É£ Making Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new customer data for prediction\n",
    "new_customer = pd.DataFrame({\n",
    "    'gender': ['Male'],\n",
    "    'SeniorCitizen': [0],\n",
    "    'Partner': ['Yes'],\n",
    "    'Dependents': ['No'],\n",
    "    'tenure': [24],\n",
    "    'PhoneService': ['Yes'],\n",
    "    'MultipleLines': ['Yes'],\n",
    "    'InternetService': ['Fiber optic'],\n",
    "    'OnlineSecurity': ['No'],\n",
    "    'Contract': ['Month-to-month'],\n",
    "    'PaperlessBilling': ['Yes'],\n",
    "    'PaymentMethod': ['Electronic check'],\n",
    "    'MonthlyCharges': [85.50],\n",
    "    'TotalCharges': [2052.00]\n",
    "})\n",
    "\n",
    "print(\"üÜï New Customer Data:\")\n",
    "print(new_customer)\n",
    "\n",
    "# Make prediction\n",
    "prediction = predict_model(final_rf, data=new_customer)\n",
    "\n",
    "print(\"\\nüîÆ Prediction Results:\")\n",
    "print(f\"Will Churn: {prediction['prediction_label'][0]}\")\n",
    "print(f\"Confidence: {prediction['prediction_score'][0]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 9Ô∏è‚É£ Streamlit Deployment\n",
    "\n",
    "## üìù Complete Streamlit App Code\n",
    "\n",
    "Save this code as `app.py` in the same folder as your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains the Streamlit app code\n",
    "# Copy this entire code block and save it as 'app.py'\n",
    "\n",
    "streamlit_app_code = '''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from pycaret.classification import load_model, predict_model\n",
    "\n",
    "# ===== PAGE CONFIGURATION =====\n",
    "st.set_page_config(\n",
    "    page_title=\"Customer Churn Prediction\",\n",
    "    page_icon=\"üìä\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# ===== LOAD MODEL =====\n",
    "@st.cache_resource\n",
    "def load_churn_model():\n",
    "    return load_model('churn_model_rf_specific')\n",
    "\n",
    "model = load_churn_model()\n",
    "\n",
    "# ===== TITLE AND DESCRIPTION =====\n",
    "st.title(\"üìä Customer Churn Prediction App\")\n",
    "st.markdown(\"\"\"\n",
    "This app predicts whether a customer will churn (leave) based on their profile.\n",
    "Fill in the customer details below and click **Predict** to see the results.\n",
    "\"\"\")\n",
    "\n",
    "# ===== SIDEBAR FOR INPUTS =====\n",
    "st.sidebar.header(\"Customer Information\")\n",
    "\n",
    "# Demographics\n",
    "st.sidebar.subheader(\"Demographics\")\n",
    "gender = st.sidebar.selectbox(\"Gender\", [\"Male\", \"Female\"])\n",
    "senior_citizen = st.sidebar.selectbox(\"Senior Citizen\", [\"No\", \"Yes\"])\n",
    "partner = st.sidebar.selectbox(\"Partner\", [\"Yes\", \"No\"])\n",
    "dependents = st.sidebar.selectbox(\"Dependents\", [\"Yes\", \"No\"])\n",
    "\n",
    "# Account Information\n",
    "st.sidebar.subheader(\"Account Information\")\n",
    "tenure = st.sidebar.slider(\"Tenure (months)\", 1, 72, 24)\n",
    "contract = st.sidebar.selectbox(\"Contract Type\", [\"Month-to-month\", \"One year\", \"Two year\"])\n",
    "paperless_billing = st.sidebar.selectbox(\"Paperless Billing\", [\"Yes\", \"No\"])\n",
    "payment_method = st.sidebar.selectbox(\n",
    "    \"Payment Method\", \n",
    "    [\"Electronic check\", \"Mailed check\", \"Bank transfer\", \"Credit card\"]\n",
    ")\n",
    "\n",
    "# Services\n",
    "st.sidebar.subheader(\"Services\")\n",
    "phone_service = st.sidebar.selectbox(\"Phone Service\", [\"Yes\", \"No\"])\n",
    "multiple_lines = st.sidebar.selectbox(\n",
    "    \"Multiple Lines\", \n",
    "    [\"Yes\", \"No\", \"No phone service\"]\n",
    ")\n",
    "internet_service = st.sidebar.selectbox(\n",
    "    \"Internet Service\", \n",
    "    [\"DSL\", \"Fiber optic\", \"No\"]\n",
    ")\n",
    "online_security = st.sidebar.selectbox(\n",
    "    \"Online Security\", \n",
    "    [\"Yes\", \"No\", \"No internet service\"]\n",
    ")\n",
    "\n",
    "# Charges\n",
    "st.sidebar.subheader(\"Billing\")\n",
    "monthly_charges = st.sidebar.number_input(\n",
    "    \"Monthly Charges (‚Ç¶)\", \n",
    "    min_value=0.0, \n",
    "    max_value=200.0, \n",
    "    value=70.0,\n",
    "    step=5.0\n",
    ")\n",
    "total_charges = st.sidebar.number_input(\n",
    "    \"Total Charges (‚Ç¶)\", \n",
    "    min_value=0.0, \n",
    "    max_value=10000.0, \n",
    "    value=1680.0,\n",
    "    step=100.0\n",
    ")\n",
    "\n",
    "# ===== CREATE PREDICTION BUTTON =====\n",
    "predict_button = st.sidebar.button(\"üîÆ Predict Churn\", type=\"primary\")\n",
    "\n",
    "# ===== MAIN AREA =====\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    st.subheader(\"üìã Customer Profile\")\n",
    "    \n",
    "    # Create input dataframe\n",
    "    input_data = pd.DataFrame({\n",
    "        'gender': [gender],\n",
    "        'SeniorCitizen': [1 if senior_citizen == \"Yes\" else 0],\n",
    "        'Partner': [partner],\n",
    "        'Dependents': [dependents],\n",
    "        'tenure': [tenure],\n",
    "        'PhoneService': [phone_service],\n",
    "        'MultipleLines': [multiple_lines],\n",
    "        'InternetService': [internet_service],\n",
    "        'OnlineSecurity': [online_security],\n",
    "        'Contract': [contract],\n",
    "        'PaperlessBilling': [paperless_billing],\n",
    "        'PaymentMethod': [payment_method],\n",
    "        'MonthlyCharges': [monthly_charges],\n",
    "        'TotalCharges': [total_charges]\n",
    "    })\n",
    "    \n",
    "    st.dataframe(input_data.T, use_container_width=True)\n",
    "\n",
    "with col2:\n",
    "    st.subheader(\"üîÆ Prediction Results\")\n",
    "    \n",
    "    if predict_button:\n",
    "        with st.spinner(\"Making prediction...\"):\n",
    "            # Make prediction\n",
    "            prediction = predict_model(model, data=input_data)\n",
    "            \n",
    "            # Extract results\n",
    "            churn_prediction = prediction['prediction_label'][0]\n",
    "            churn_probability = prediction['prediction_score'][0]\n",
    "            \n",
    "            # Display results\n",
    "            if churn_prediction == \"Yes\":\n",
    "                st.error(\"‚ö†Ô∏è HIGH RISK: Customer likely to churn\")\n",
    "                st.metric(\n",
    "                    \"Churn Probability\", \n",
    "                    f\"{churn_probability:.1%}\",\n",
    "                    delta=\"High Risk\",\n",
    "                    delta_color=\"inverse\"\n",
    "                )\n",
    "                st.warning(\"\"\"\n",
    "                **Recommended Actions:**\n",
    "                - Offer retention discount\n",
    "                - Upgrade to longer contract\n",
    "                - Improve customer service\n",
    "                - Provide loyalty rewards\n",
    "                \"\"\")\n",
    "            else:\n",
    "                st.success(\"‚úÖ LOW RISK: Customer likely to stay\")\n",
    "                st.metric(\n",
    "                    \"Retention Probability\", \n",
    "                    f\"{(1 - churn_probability):.1%}\",\n",
    "                    delta=\"Low Risk\",\n",
    "                    delta_color=\"normal\"\n",
    "                )\n",
    "                st.info(\"\"\"\n",
    "                **Recommended Actions:**\n",
    "                - Continue excellent service\n",
    "                - Offer upsell opportunities\n",
    "                - Request feedback/reviews\n",
    "                - Cross-sell additional services\n",
    "                \"\"\")\n",
    "    else:\n",
    "        st.info(\"üëà Fill in customer details and click 'Predict Churn'\")\n",
    "\n",
    "# ===== FOOTER =====\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"\"\"\n",
    "<div style='text-align: center'>\n",
    "    <p>Built with ‚ù§Ô∏è using PyCaret and Streamlit</p>\n",
    "    <p>Data Science Lead: Victor Bolade | Blossom Academy</p>\n",
    "</div>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "'''\n",
    "\n",
    "# Save the Streamlit app code to a file\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(streamlit_app_code)\n",
    "\n",
    "print(\"‚úÖ Streamlit app code saved as 'app.py'\")\n",
    "print(\"\\nTo run the app, use this command in your terminal:\")\n",
    "print(\"streamlit run app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ How to Run Streamlit App\n",
    "\n",
    "### Step 1: Make sure you have the model saved\n",
    "```python\n",
    "# This was already done earlier in the notebook\n",
    "save_model(final_rf, 'churn_model_rf_specific')\n",
    "```\n",
    "\n",
    "### Step 2: Save the app.py file\n",
    "The code above already saved `app.py` in your current directory.\n",
    "\n",
    "### Step 3: Run Streamlit\n",
    "Open your terminal/command prompt and run:\n",
    "```bash\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "### Step 4: Access the app\n",
    "Your browser will automatically open to `http://localhost:8501`\n",
    "\n",
    "## üåç Deploy to Streamlit Cloud (FREE!)\n",
    "\n",
    "1. Push your code to GitHub (app.py + model file)\n",
    "2. Go to https://share.streamlit.io\n",
    "3. Connect your GitHub repository\n",
    "4. Deploy with one click!\n",
    "5. Get a public URL like: `https://yourapp.streamlit.app`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîü Summary: Complete Workflows\n",
    "\n",
    "## üìã Workflow 1: Full Automation (compare_models)\n",
    "\n",
    "```python\n",
    "# 1. Clean data\n",
    "data = pd.read_csv('data.csv')\n",
    "data = data.drop(columns=['customerID'])\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
    "\n",
    "# 2. Setup PyCaret\n",
    "clf = setup(\n",
    "    data=data,\n",
    "    target='Churn',\n",
    "    session_id=42,\n",
    "    normalize=True,\n",
    "    fix_imbalance=True,  # Handle imbalanced data\n",
    "    silent=True\n",
    ")\n",
    "\n",
    "# 3. Compare models\n",
    "best = compare_models()\n",
    "print(f\"Best Algorithm: {type(best).__name__}\")\n",
    "\n",
    "# 4. Tune (optional)\n",
    "tuned = tune_model(best)\n",
    "\n",
    "# 5. Finalize\n",
    "final = finalize_model(tuned)\n",
    "\n",
    "# 6. Save\n",
    "save_model(final, 'model')\n",
    "```\n",
    "\n",
    "## üéØ Workflow 2: Specific Model (faster)\n",
    "\n",
    "```python\n",
    "# 1. Clean data (same as above)\n",
    "data = pd.read_csv('data.csv')\n",
    "data = data.drop(columns=['customerID'])\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
    "\n",
    "# 2. Setup PyCaret\n",
    "clf = setup(\n",
    "    data=data,\n",
    "    target='Churn',\n",
    "    session_id=42,\n",
    "    normalize=True,\n",
    "    fix_imbalance=True,\n",
    "    silent=True\n",
    ")\n",
    "\n",
    "# 3. Create specific model\n",
    "model = create_model('rf')  # or 'xgboost', 'lightgbm', 'catboost'\n",
    "print(f\"Model: {type(model).__name__}\")\n",
    "\n",
    "# 4. Tune (optional)\n",
    "tuned = tune_model(model)\n",
    "\n",
    "# 5. Finalize\n",
    "final = finalize_model(tuned)\n",
    "\n",
    "# 6. Save\n",
    "save_model(final, 'model')\n",
    "```\n",
    "\n",
    "## ‚ö° Workflow 3: Minimal (no tuning)\n",
    "\n",
    "```python\n",
    "# 1. Clean data\n",
    "data = pd.read_csv('data.csv')\n",
    "data = data.drop(columns=['customerID'])\n",
    "\n",
    "# 2. Setup\n",
    "clf = setup(data=data, target='Churn', session_id=42, silent=True)\n",
    "\n",
    "# 3. Train\n",
    "model = create_model('rf')\n",
    "\n",
    "# 4. Finalize and save\n",
    "final = finalize_model(model)\n",
    "save_model(final, 'model')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ Key Parameters Reference\n",
    "\n",
    "## üìä setup() Parameters\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "|-----------|------|---------|-------------|\n",
    "| `data` | DataFrame | Required | Your pandas DataFrame |\n",
    "| `target` | str | Required | Target column name |\n",
    "| `session_id` | int | None | Random seed for reproducibility |\n",
    "| `normalize` | bool | False | Scale numeric features |\n",
    "| `transformation` | bool | False | Apply power transformations |\n",
    "| `fix_imbalance` | bool | False | Handle class imbalance with SMOTE |\n",
    "| `remove_outliers` | bool | False | Remove outliers |\n",
    "| `remove_multicollinearity` | bool | False | Remove correlated features |\n",
    "| `categorical_features` | list | None | List of categorical columns |\n",
    "| `numeric_features` | list | None | List of numeric columns |\n",
    "| `ignore_features` | list | None | Columns to ignore |\n",
    "| `handle_unknown_categorical` | bool | True | Handle unseen categories |\n",
    "| `silent` | bool | False | Suppress output |\n",
    "\n",
    "## üîç compare_models() Parameters\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "|-----------|------|---------|-------------|\n",
    "| `sort` | str | 'Accuracy' | Metric to sort by |\n",
    "| `n_select` | int | 1 | Number of models to return |\n",
    "| `fold` | int | 10 | Cross-validation folds |\n",
    "| `exclude` | list | None | Models to exclude |\n",
    "| `turbo` | bool | True | Faster comparison |\n",
    "\n",
    "## ‚öôÔ∏è tune_model() Parameters\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "|-----------|------|---------|-------------|\n",
    "| `optimize` | str | 'Accuracy' | Metric to optimize |\n",
    "| `n_iter` | int | 10 | Number of iterations |\n",
    "| `fold` | int | 10 | Cross-validation folds |\n",
    "| `custom_grid` | dict | None | Custom hyperparameter grid |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Common Questions & Answers\n",
    "\n",
    "## ‚ùì Q1: Do I HAVE to use compare_models()?\n",
    "**A:** No! You can directly create a specific model with `create_model('rf')` if you already know which algorithm to use.\n",
    "\n",
    "## ‚ùì Q2: Do I HAVE to tune the model?\n",
    "**A:** No! Tuning is optional. You can skip it and go straight to `finalize_model(best_model)`.\n",
    "\n",
    "## ‚ùì Q3: How do I know which algorithm was selected?\n",
    "**A:** Use `print(type(best_model).__name__)` after `compare_models()`.\n",
    "\n",
    "## ‚ùì Q4: What if my dataset is imbalanced?\n",
    "**A:** Set `fix_imbalance=True` in `setup()`. PyCaret will automatically use SMOTE.\n",
    "\n",
    "## ‚ùì Q5: Can I use my own custom algorithm?\n",
    "**A:** Yes! You can pass any scikit-learn compatible estimator to `create_model()`.\n",
    "\n",
    "## ‚ùì Q6: How do I deploy to production?\n",
    "**A:** Use Streamlit (easiest), Flask, or FastAPI. PyCaret models work with all frameworks.\n",
    "\n",
    "## ‚ùì Q7: Can I use PyCaret with deep learning?\n",
    "**A:** For deep learning, use PyTorch or TensorFlow. PyCaret focuses on classical ML and gradient boosting.\n",
    "\n",
    "## ‚ùì Q8: What's the difference between finalize_model() and create_model()?\n",
    "**A:** `create_model()` trains on training set only. `finalize_model()` retrains on the entire dataset for deployment.\n",
    "\n",
    "## ‚ùì Q9: Can I use PyCaret for regression?\n",
    "**A:** Yes! Use `from pycaret.regression import *` instead of classification.\n",
    "\n",
    "## ‚ùì Q10: Does PyCaret work with categorical data?\n",
    "**A:** Yes! PyCaret automatically handles categorical encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1Ô∏è‚É£3Ô∏è‚É£ Best Practices for Production\n",
    "\n",
    "## ‚úÖ DO\n",
    "\n",
    "1. **Always clean data before PyCaret** - Remove IDs, handle missing values\n",
    "2. **Use session_id** - For reproducible results\n",
    "3. **Handle imbalance** - Set `fix_imbalance=True` if target is imbalanced\n",
    "4. **Always finalize** - Call `finalize_model()` before deployment\n",
    "5. **Save preprocessing** - PyCaret saves both model AND preprocessing pipeline\n",
    "6. **Use cross-validation** - Default 10-fold is good, 5-fold for large datasets\n",
    "7. **Version your models** - Use descriptive names: `churn_model_v2.pkl`\n",
    "8. **Monitor performance** - Track metrics in production\n",
    "\n",
    "## ‚ùå DON'T\n",
    "\n",
    "1. **Don't skip data cleaning** - PyCaret is not magic, garbage in = garbage out\n",
    "2. **Don't use setup() twice** - Creates new experiment each time\n",
    "3. **Don't deploy without finalize** - Model won't perform optimally\n",
    "4. **Don't ignore class imbalance** - Can lead to poor performance\n",
    "5. **Don't over-tune** - Diminishing returns after 50 iterations\n",
    "6. **Don't trust compare_models blindly** - Validate on hold-out test set\n",
    "7. **Don't use base environment** - Always create conda environment\n",
    "8. **Don't hard-code paths** - Use relative paths or environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1Ô∏è‚É£4Ô∏è‚É£ Next Steps\n",
    "\n",
    "## üéì For Learning\n",
    "\n",
    "1. Try different datasets from Kaggle\n",
    "2. Experiment with all classification algorithms\n",
    "3. Learn about model interpretability (SHAP, LIME)\n",
    "4. Practice hyperparameter tuning\n",
    "5. Build a portfolio project\n",
    "\n",
    "## üöÄ For Production\n",
    "\n",
    "1. Set up MLflow for experiment tracking\n",
    "2. Create CI/CD pipeline for model deployment\n",
    "3. Implement model monitoring\n",
    "4. Add authentication to Streamlit app\n",
    "5. Deploy on cloud (AWS, Azure, GCP)\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **PyCaret Documentation:** https://pycaret.org\n",
    "- **Streamlit Documentation:** https://docs.streamlit.io\n",
    "- **PyCaret Tutorials:** https://pycaret.gitbook.io\n",
    "- **Streamlit Gallery:** https://streamlit.io/gallery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéâ Congratulations!\n",
    "\n",
    "You've learned:\n",
    "\n",
    "‚úÖ What PyCaret is and why it's powerful\n",
    "\n",
    "‚úÖ What Streamlit is and how to deploy ML apps\n",
    "\n",
    "‚úÖ Complete ML workflow from data cleaning to deployment\n",
    "\n",
    "‚úÖ Two approaches: automated (compare_models) vs manual (create_model)\n",
    "\n",
    "‚úÖ Handling imbalanced datasets\n",
    "\n",
    "‚úÖ Optional steps (tuning, outlier removal, etc.)\n",
    "\n",
    "‚úÖ Production-ready best practices\n",
    "\n",
    "---\n",
    "\n",
    "**Created by:** Victor Bolade - Data Science Lead Instructor\n",
    "\n",
    "**Institution:** Blossom Academy, Ghana\n",
    "\n",
    "**Program:** AI, Data Science & Machine Learning (WFP Partnership)\n",
    "\n",
    "**Date:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Remember\n",
    "\n",
    "> \"The best model is the one that solves your business problem, not the one with the highest accuracy.\"\n",
    "\n",
    "Good luck with your machine learning journey! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
